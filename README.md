# Modular Pipeline

A scalable, multi-module Spring Boot application designed to collect, process, and analyze sensor data at scale with real-time monitoring and anomaly detection capabilities.

## ğŸ— Architecture

The project is structured into several modules:

- **api**: Core API definitions and interfaces
- **common [pipeline-common]**: Shared utilities and common functionality
- **ingestion**: Sensor data ingestion handlers
- **kafka**: Message broker integration for stream processing
- **monitoring**: System health and metrics monitoring
- **processing**: Data processing and analysis pipeline
- **prometheus**: Metrics collection and exporters
- **storage**: Data persistence layer with TimescaleDB integration

## ğŸš€ Features

- Real-time sensor data ingestion from multiple sources
- Scalable stream processing using Apache Kafka
- Time-series data storage with TimescaleDB
- Comprehensive monitoring with Prometheus and Grafana
- Anomaly detection and alerting
- Modular architecture for easy extension

## ğŸ“‹ Prerequisites

- Java 11 or higher
- Docker and Docker Compose
- Maven
- TimescaleDB
- Apache Kafka
- Prometheus
- Grafana

## ğŸ›  Setup

1. Clone the repository:
```bash
git clone https://github.com/yourusername/modular-pipeline.git
cd modular-pipeline
```

2. Start the required services using Docker Compose:
```bash
cd kafka
docker-compose up -d

cd ../prometheus
docker-compose up -d
```

3. Build the project:
```bash
mvn clean install
```

4. Configure your database settings in `storage/src/main/resources/application.properties`

5. Start the application:
```bash
java -jar target/modular-pipeline.jar
```

## ğŸ“Š Monitoring Setup and Configuration

### Prometheus Setup

1. Verify Prometheus is running:
```bash
docker ps | grep prometheus
```

2. Access the Prometheus UI at `http://localhost:9090`

3. Verify target scraping is working:
    - Navigate to Status > Targets
    - Check that all application endpoints are in "UP" state

### Grafana Setup

1. Access Grafana at `http://localhost:3000`
    - Default credentials: admin/admin

2. Add Data Sources:
    - Click "Configuration" > "Data Sources"
    - Add Prometheus:
        - URL: `http://prometheus:9090`
        - Access: Browser
        - Click "Test & Save"
    - Add TimescaleDB:
        - Type: PostgreSQL
        - Host: `timescaledb:5432`
        - Database: Your database name
        - User & Password: Your credentials
        - SSL Mode: disable
        - Version: 12+

3. Import Dashboards:
    - Click "+ Import"
    - Upload provided JSON dashboard files from `monitoring/dashboards/`

### Available Dashboards

1. **Sensor Overview Dashboard**
    - Real-time sensor readings
    - Historical trends
    - Sensor health status
    - Path: `monitoring/dashboards/sensor-overview.json`

2. **System Metrics Dashboard**
    - JVM metrics
    - API endpoint latency
    - Error rates
    - Resource utilization
    - Path: `monitoring/dashboards/system-metrics.json`

3. **Kafka Monitoring Dashboard**
    - Consumer lag
    - Message throughput
    - Partition distribution
    - Producer metrics
    - Path: `monitoring/dashboards/kafka-metrics.json`

4. **Anomaly Detection Dashboard**
    - Real-time anomaly detection
    - Historical anomaly patterns
    - Alert history
    - Investigation tools
    - Path: `monitoring/dashboards/anomaly-detection.json`

### Alert Configuration

1. Navigate to Alerting in Grafana
2. Import alert rules from `monitoring/alert-rules/`
3. Configure notification channels:
    - Email
    - Slack
    - PagerDuty
    - Custom webhooks

### Dashboard Customization

Each dashboard can be customized:
1. Click the dashboard settings icon (âš™ï¸)
2. Use "Add Panel" to create new visualizations
3. Edit existing panels using the panel menu
4. Save changes to your organization

### Metrics Collection

Application metrics are exposed at:
- Application metrics: `/actuator/prometheus`
- JVM metrics: `/actuator/metrics`
- Health check: `/actuator/health`


## ğŸ— Project Structure

```
modular-pipeline/
â”œâ”€â”€ api/                    # Core API definitions
â”œâ”€â”€ common/                 # Shared utilities
â”œâ”€â”€ ingestion/             # Data ingestion handlers
â”œâ”€â”€ kafka/                 # Kafka integration
â”‚   â””â”€â”€ docker-compose.yml
â”œâ”€â”€ monitoring/            # System monitoring
â”œâ”€â”€ processing/           # Data processing pipeline
â”œâ”€â”€ prometheus/           # Metrics collection
â”‚   â”œâ”€â”€ docker-compose.yml
â”‚   â””â”€â”€ prometheus.yml
â”œâ”€â”€ src/                  # Core application code
â”œâ”€â”€ storage/              # Data persistence layer
â”‚   â”œâ”€â”€ pom.xml
â”‚   â””â”€â”€ storage.iml
â””â”€â”€ pom.xml              # Root Maven configuration
```

## ğŸ“ˆ Metrics and Dashboards

The application provides several pre-configured Grafana dashboards:
- Sensor Data Overview
- System Performance Metrics
- Anomaly Detection Dashboard
- Kafka Stream Metrics

## ğŸ”§ Configuration

Key configuration files:
- `prometheus.yml`: Prometheus scraping and alerting rules
- `docker-compose.yml`: Container configurations
- `storage.iml`: Database connection settings

## ğŸ¤ Contributing

1. Fork the repository
2. Create a feature branch
3. Commit your changes
4. Push to the branch
5. Create a Pull Request

## ğŸ“ License

[![MIT License](https://img.shields.io/badge/License-MIT-green.svg)](https://choosealicense.com/licenses/mit/)

## ğŸ“ Support

For support and queries, please create an issue in the repository.